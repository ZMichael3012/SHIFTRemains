{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"MyGenerator.ipynb","version":"0.3.2","provenance":[],"private_outputs":true,"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"_tYpOexlJKE2","colab_type":"code","colab":{}},"source":["import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","from google.colab import files\n","import pickle\n","%matplotlib inline"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"6bi9XPP8JoPz","colab_type":"code","colab":{}},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"RoQIEsjoJqUK","colab_type":"code","colab":{}},"source":["df = pd.read_csv('/content/drive/My Drive/SHIFT/готовые csv/comment.csv')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"p1AvmqlGKCKt","colab_type":"code","colab":{}},"source":["lines = [str(line) for line in df['text']]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZsijC9ZENiYE","colab_type":"code","colab":{}},"source":["sorted(lines, key=len)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"mizch6GlKpHI","colab_type":"code","colab":{}},"source":["from nltk.tokenize import WordPunctTokenizer\n","tokenizer = WordPunctTokenizer()\n","\n","lines = [' '.join(tokenizer.tokenize(word.lower())) for word in lines]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"MS3dUBv2LDas","colab_type":"code","colab":{}},"source":["from tqdm import tqdm\n","from collections import defaultdict, Counter\n","\n","# special tokens: \n","# - unk represents absent tokens, \n","# - eos is a special token after the end of sequence\n","\n","UNK, EOS = \"_UNK_\", \"_EOS_\"\n","\n","def count_ngrams(lines, n):\n","    \"\"\"\n","    Count how many times each word occured after (n - 1) previous words\n","    :param lines: an iterable of strings with space-separated tokens\n","    :returns: a dictionary { tuple(prefix_tokens): {next_token_1: count_1, next_token_2: count_2}}\n","\n","    When building counts, please consider the following two edge cases\n","    - if prefix is shorter than (n - 1) tokens, it should be padded with UNK. For n=3,\n","      empty prefix: \"\" -> (UNK, UNK)\n","      short prefix: \"the\" -> (UNK, the)\n","      long prefix: \"the new approach\" -> (new, approach)\n","    - you should add a special token, EOS, at the end of each sequence\n","      \"... with deep neural networks .\" -> (..., with, deep, neural, networks, ., EOS)\n","      count the probability of this token just like all others.\n","    \"\"\"\n","    counts = defaultdict(Counter)\n","    # counts[(word1, word2)][word3] = how many times word3 occured after (word1, word2)\n","\n","    for line in tqdm(lines):\n","      line = (UNK + ' ') * (n - 1) + line + ' ' + EOS\n","      tokens = line.split()\n","      for i in range(n - 1, len(tokens)):\n","        prefix = tokens[i - n + 1 : i]\n","        counts[tuple(prefix)][tokens[i]] += 1\n","    \n","    return counts"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"6DFbD4P0LX1p","colab_type":"code","colab":{}},"source":["class NGramLanguageModel:    \n","    def __init__(self, lines, n):\n","        \"\"\" \n","        Train a simple count-based language model: \n","        compute probabilities P(w_t | prefix) given ngram counts\n","        \n","        :param n: computes probability of next token given (n - 1) previous words\n","        :param lines: an iterable of strings with space-separated tokens\n","        \"\"\"\n","        assert n >= 1\n","        self.n = n\n","    \n","        counts = count_ngrams(lines, self.n)\n","        \n","        # compute token proabilities given counts\n","        self.probs = defaultdict(Counter)\n","        # probs[(word1, word2)][word3] = P(word3 | word1, word2)\n","        \n","        # populate self.probs with actual probabilities\n","        counts_of_prefix = Counter()\n","        for key, value in counts.items():\n","          counts_of_prefix[key] = sum(value.values())\n","        \n","        for key, value in counts.items():\n","          for token in value:\n","            self.probs[key][token] = value[token] / counts_of_prefix[key]\n","            \n","    def get_possible_next_tokens(self, prefix):\n","        \"\"\"\n","        :param prefix: string with space-separated prefix tokens\n","        :returns: a dictionary {token : it's probability} for all tokens with positive probabilities\n","        \"\"\"\n","        prefix = prefix.split()\n","        prefix = prefix[max(0, len(prefix) - self.n + 1):]\n","        prefix = [ UNK ] * (self.n - 1 - len(prefix)) + prefix\n","        return self.probs[tuple(prefix)]\n","    \n","    def get_next_token_prob(self, prefix, next_token):\n","        \"\"\"\n","        :param prefix: string with space-separated prefix tokens\n","        :param next_token: the next token to predict probability for\n","        :returns: P(next_token|prefix) a single number, 0 <= P <= 1\n","        \"\"\"\n","        return self.get_possible_next_tokens(prefix).get(next_token, 0)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"LstNe5k5MdC0","colab_type":"code","colab":{}},"source":["lm = NGramLanguageModel(lines, n=4)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ORVdAz69LzmP","colab_type":"code","colab":{}},"source":["def get_next_token(lm, prefix, temperature=0.4):\n","    \"\"\"\n","    return next token after prefix;\n","    :param temperature: samples proportionally to lm probabilities ^ temperature\n","        if temperature == 0, always takes most likely token. Break ties arbitrarily.\n","    \"\"\"\n","    probs_dict = lm.get_possible_next_tokens(prefix)\n","    probs = np.array(list(probs_dict.values()))  \n","    if temperature == 0:\n","      return list(probs_dict.keys())[np.argmax(probs)]\n","    else:\n","      probs = probs ** (1 / temperature)\n","      probs /= sum(probs)\n","      return list(probs_dict.keys())[np.random.choice(len(probs),p = probs)]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"zU4szXjlL1-Z","colab_type":"code","colab":{}},"source":["from collections import Counter\n","\n","prefix = 'космос' # <- your ideas :)\n","\n","for i in range(100):\n","    prefix += ' ' + get_next_token(lm, prefix)\n","    if prefix.endswith(EOS) or len(lm.get_possible_next_tokens(prefix)) == 0:\n","        break\n","        \n","print(prefix)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"wKzan9dNMUhd","colab_type":"code","colab":{}},"source":["with open('lmodel.pkl', 'wb') as f:\n","  pickle.dump(lm, f)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"zoj5ukJphbVK","colab_type":"code","colab":{}},"source":["files.download('lmodel.pkl')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"EIaM678cht8B","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}